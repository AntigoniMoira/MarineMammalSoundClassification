{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **.wav Files and Metadata Scraper**\n","\n","The following code downloads the audio files of **'Best of' cuts** section from the [Watkins Marine Mammal Sound Database](https://whoicf2.whoi.edu/science/B/whalesounds/index.cfm) along with their metadata. The 'Best of' cuts section contains 1,694 sound cuts deemed to be of higher sound quality and lower noise from 32 different species."],"metadata":{"id":"reaA4LfG84cs"}},{"cell_type":"code","source":["# Importing the drive module from google.colab library\n","from google.colab import drive\n","\n","# Mounting the Google Drive to the Colab environment\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pT3ZCeoQVrQP","executionInfo":{"status":"ok","timestamp":1719219826083,"user_tz":-180,"elapsed":27040,"user":{"displayName":"ΜΥΡΣΙΝΗ ΚΑΡΑΚΑΣΟΓΛΟΥ","userId":"17910426019924694642"}},"outputId":"eb6df2b5-531d-44a6-b93a-35111a95cd4b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Importing necessary libraries\n","from bs4 import BeautifulSoup\n","import urllib\n","import re\n","import requests\n","import json\n","import os\n","\n","project_path = '/content/drive/My Drive/GitHub/MarineMammalSoundClassification/'"],"metadata":{"id":"AzBJRmMhVwCW","executionInfo":{"status":"ok","timestamp":1719219831202,"user_tz":-180,"elapsed":1032,"user":{"displayName":"ΜΥΡΣΙΝΗ ΚΑΡΑΚΑΣΟΓΛΟΥ","userId":"17910426019924694642"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### **Species List**\n","\n","Using the following code, a list of all available mammals was created, including their common and scientific names along with their codes. The resulting list is stored in the file `/metadata/species.json` for convenient future access."],"metadata":{"id":"Rvs2iU_m_w4c"}},{"cell_type":"code","source":["# URL of the Watkins Marine Mammal Sound Dataset 'BEST OF' CUTS page to scrape\n","best_of_link = 'https://whoicf2.whoi.edu/science/B/whalesounds/index.cfm'\n","\n","# Open the URL and read its content\n","url = urllib.request.urlopen(best_of_link)\n","content = url.read()\n","\n","# Create a BeautifulSoup object to parse the HTML content\n","soup = BeautifulSoup(content, 'html.parser')\n","\n","# Dictionary to store species information\n","species = {}\n","\n","# Find all div elements with class 'large-3 columns'\n","div_list = soup.find_all('div', class_='large-3 columns')\n","\n","for sdiv in div_list:\n","    try:\n","        common_name = sdiv.a.div.h3.get_text()\n","        # Generate a folder name from the common name\n","        folder = common_name.replace(\" \", \"\").replace(\",\", \"_\").replace(\"-\", \"_\")\n","        scientific_name = sdiv.a.div.img['src'].split('/')[-1].replace(\".png\", \"\").replace(\"-\", \" \")\n","        code = sdiv.a['href'].split('code=')[-1]\n","        # Store species information in the dictionary\n","        species[folder] = {\n","            'common_name': common_name,\n","            'scientific_name': scientific_name,\n","            'code': code\n","        }\n","    except Exception as e:\n","        # Skip if a div is not in the expected formand and continue to the next iteration\n","        continue\n","\n","# Convert the dictionary to JSON format\n","species_json = json.dumps(species, indent=4)\n","\n","# Write the JSON data to a file\n","with open(os.path.join(project_path,'metadata/species.json'), 'w') as fp:\n","    fp.write(species_json)"],"metadata":{"id":"4wZyE8pgbJeT","executionInfo":{"status":"ok","timestamp":1719219848330,"user_tz":-180,"elapsed":1677,"user":{"displayName":"ΜΥΡΣΙΝΗ ΚΑΡΑΚΑΣΟΓΛΟΥ","userId":"17910426019924694642"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### **Download .wav files**\n","\n","\n","The function `download_species_wav_files` was utilized to download all available .wav files for each species in species.json. Its code was used to construct the necessary link."],"metadata":{"id":"R63n6TF1BYDV"}},{"cell_type":"code","source":["def download_species_wav_files(link, output_path):\n","    \"\"\"\n","    Download audio files (wav, mp3, ogg, wma) linked on a webpage.\n","\n","    Args:\n","        link (str): The URL of the webpage containing the audio links.\n","        output_path (str): The directory where the downloaded files will be saved.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Open the URL and read its content\n","    url = urllib.request.urlopen(link)\n","    content = url.read()\n","\n","    # Create a BeautifulSoup object to parse the HTML content\n","    soup = BeautifulSoup(content, 'html.parser')\n","\n","    # Find all anchor elements with links to audio files\n","    links = [a['href'] for a in soup.find_all('a', href=re.compile(r'.*\\.(mp3|wav|ogg|wma)'))]\n","\n","    print(\"{} Audios Found\".format(len(links)))\n","\n","    # Headers for the request\n","    headers = {\n","        \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:91.0) Gecko/20100101 Firefox/91.0\"\n","    }\n","\n","    # Download each audio file\n","    for wav_link in links:\n","        # Construct the complete URL of the audio file\n","        u = 'https://whoicf2.whoi.edu' + wav_link\n","        # Define the path to save the audio file\n","        wav_file = os.path.join(output_path, wav_link.split(\"/\")[-1])\n","        # Download and save the audio file\n","        with open(wav_file, \"wb\") as f_out:\n","            f_out.write(requests.get(u, headers=headers).content)\n"],"metadata":{"id":"yfNfQhuFccmY","executionInfo":{"status":"ok","timestamp":1719219863863,"user_tz":-180,"elapsed":443,"user":{"displayName":"ΜΥΡΣΙΝΗ ΚΑΡΑΚΑΣΟΓΛΟΥ","userId":"17910426019924694642"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["with open(os.path.join(project_path,'metadata/species.json')) as f:\n","    species = json.load(f)\n","\n","# Iterate over each species in the dictionary\n","for key, value in species.items():\n","    print(\"Downloading files for:\", key)\n","\n","    # Create a folder for the mammal if it doesn't exist\n","    mammal_folder = os.path.join(project_path, 'data/', key)\n","    if not os.path.exists(mammal_folder):\n","        os.makedirs(mammal_folder)\n","\n","    # Construct the URL for the mammal's audio files\n","    mammal_link = 'https://whoicf2.whoi.edu/science/B/whalesounds/bestOf.cfm?code=' + value['code']\n","\n","    # Download the audio files for the mammal and save them in the folder\n","    download_species_wav_files(mammal_link, mammal_folder)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NzyGkAwVWVue","executionInfo":{"status":"ok","timestamp":1719222132808,"user_tz":-180,"elapsed":2261078,"user":{"displayName":"ΜΥΡΣΙΝΗ ΚΑΡΑΚΑΣΟΓΛΟΥ","userId":"17910426019924694642"}},"outputId":"a37bd28d-73a1-4b24-9efb-b368926103f1","collapsed":true},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading files for: AtlanticSpottedDolphin\n","58 Audios Found\n","Downloading files for: BeardedSeal\n","37 Audios Found\n","Downloading files for: Beluga_WhiteWhale\n","50 Audios Found\n","Downloading files for: BottlenoseDolphin\n","24 Audios Found\n","Downloading files for: BowheadWhale\n","60 Audios Found\n","Downloading files for: ClymeneDolphin\n","63 Audios Found\n","Downloading files for: CommonDolphin\n","52 Audios Found\n","Downloading files for: FalseKillerWhale\n","59 Audios Found\n","Downloading files for: Fin_FinbackWhale\n","50 Audios Found\n","Downloading files for: Fraser'sDolphin\n","87 Audios Found\n","Downloading files for: Grampus_Risso'sDolphin\n","67 Audios Found\n","Downloading files for: HarpSeal\n","47 Audios Found\n","Downloading files for: HumpbackWhale\n","64 Audios Found\n","Downloading files for: KillerWhale\n","35 Audios Found\n","Downloading files for: LeopardSeal\n","10 Audios Found\n","Downloading files for: Long_FinnedPilotWhale\n","70 Audios Found\n","Downloading files for: MelonHeadedWhale\n","63 Audios Found\n","Downloading files for: MinkeWhale\n","17 Audios Found\n","Downloading files for: Narwhal\n","50 Audios Found\n","Downloading files for: NorthernRightWhale\n","54 Audios Found\n","Downloading files for: PantropicalSpottedDolphin\n","66 Audios Found\n","Downloading files for: RossSeal\n","50 Audios Found\n","Downloading files for: Rough_ToothedDolphin\n","50 Audios Found\n","Downloading files for: Short_Finned(Pacific)PilotWhale\n","67 Audios Found\n","Downloading files for: SouthernRightWhale\n","25 Audios Found\n","Downloading files for: SpermWhale\n","75 Audios Found\n","Downloading files for: SpinnerDolphin\n","114 Audios Found\n","Downloading files for: StripedDolphin\n","81 Audios Found\n","Downloading files for: Walrus\n","38 Audios Found\n","Downloading files for: WeddellSeal\n","2 Audios Found\n","Downloading files for: White_beakedDolphin\n","57 Audios Found\n","Downloading files for: White_sidedDolphin\n","55 Audios Found\n"]}]},{"cell_type":"markdown","source":["### **Get matadata for each .wav files**\n","\n","The def get_wav_metadata function was employed to scrape the available metadata for each .wav file previously downloaded and saving them in the `/metadata/wav_metadata.json` file for potential future use."],"metadata":{"id":"rDBhwAUFDIKO"}},{"cell_type":"code","source":["def get_wav_metadata(wav_metadata_link):\n","    \"\"\"\n","    Scrape metadata from a WAV file's webpage.\n","\n","    Args:\n","        wav_metadata_link (str): The URL of the webpage containing the WAV file's metadata.\n","\n","    Returns:\n","        dict: A dictionary containing the extracted metadata.\n","    \"\"\"\n","    # Open the URL and read its content\n","    url = urllib.request.urlopen(wav_metadata_link)\n","    content = url.read()\n","\n","    # Create a BeautifulSoup object to parse the HTML content\n","    soup = BeautifulSoup(content, 'html.parser')\n","\n","    # Dictionary to store metadata\n","    metadata = {}\n","\n","    # Find all tables on the webpage\n","    tables = soup.find_all('table')\n","\n","    # The metadata table is the second table on the page\n","    meta_table = tables[1]\n","\n","    # Iterate over each row in the metadata table\n","    for row in meta_table.find_all('tr'):\n","        cells = row.find_all('td')\n","        # Check if the row contains two cells (key and value)\n","        if len(cells) == 2:\n","            # Add the key-value pair to the metadata dictionary\n","            metadata[cells[0].text] = cells[1].text\n","\n","    return metadata\n"],"metadata":{"id":"Kb84L2_-zQUW","executionInfo":{"status":"ok","timestamp":1719222227720,"user_tz":-180,"elapsed":512,"user":{"displayName":"ΜΥΡΣΙΝΗ ΚΑΡΑΚΑΣΟΓΛΟΥ","userId":"17910426019924694642"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Initialize an empty dictionary to store metadata\n","metadata = {}\n","\n","with open(os.path.join(project_path,'metadata/species.json')) as f:\n","    species = json.load(f)\n","\n","# Iterate over each species in the dictionary\n","for key, value in species.items():\n","    print(\"Creating metadata for:\", key)\n","\n","    # Construct the path to the folder containing WAV files for the current species\n","    mammal_folder = os.path.join(project_path, 'data/', key)\n","\n","    # Get the list of WAV files in the species folder\n","    list_of_wav = os.listdir(mammal_folder)\n","\n","    for wav_file in list_of_wav:\n","        # Extract the WAV code from the file name\n","        wav_code = wav_file[:-4]\n","\n","        # Construct the URL for the WAV file's metadata\n","        wav_metadata_link = 'https://whoicf2.whoi.edu/science/B/whalesounds/metaData.cfm?RN=' + wav_code\n","\n","        # Get metadata for the WAV file\n","        wav_meta = get_wav_metadata(wav_metadata_link)\n","\n","        # Add the metadata to the metadata dictionary using the WAV code as the key\n","        metadata[wav_code] = wav_meta\n","\n","# Convert the metadata dictionary to JSON format\n","metadata_json = json.dumps(metadata, indent=4)\n","\n","# Write the JSON data to a file\n","with open(os.path.join(project_path,'metadata/wav_metadata.json'), 'w') as fp:\n","    fp.write(metadata_json)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gViF70rHwK8H","executionInfo":{"status":"ok","timestamp":1719222863272,"user_tz":-180,"elapsed":632267,"user":{"displayName":"ΜΥΡΣΙΝΗ ΚΑΡΑΚΑΣΟΓΛΟΥ","userId":"17910426019924694642"}},"outputId":"d3063325-aa46-4a2d-8926-fd053f01c756"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating metadata for: AtlanticSpottedDolphin\n","Creating metadata for: BeardedSeal\n","Creating metadata for: Beluga_WhiteWhale\n","Creating metadata for: BottlenoseDolphin\n","Creating metadata for: BowheadWhale\n","Creating metadata for: ClymeneDolphin\n","Creating metadata for: CommonDolphin\n","Creating metadata for: FalseKillerWhale\n","Creating metadata for: Fin_FinbackWhale\n","Creating metadata for: Fraser'sDolphin\n","Creating metadata for: Grampus_Risso'sDolphin\n","Creating metadata for: HarpSeal\n","Creating metadata for: HumpbackWhale\n","Creating metadata for: KillerWhale\n","Creating metadata for: LeopardSeal\n","Creating metadata for: Long_FinnedPilotWhale\n","Creating metadata for: MelonHeadedWhale\n","Creating metadata for: MinkeWhale\n","Creating metadata for: Narwhal\n","Creating metadata for: NorthernRightWhale\n","Creating metadata for: PantropicalSpottedDolphin\n","Creating metadata for: RossSeal\n","Creating metadata for: Rough_ToothedDolphin\n","Creating metadata for: Short_Finned(Pacific)PilotWhale\n","Creating metadata for: SouthernRightWhale\n","Creating metadata for: SpermWhale\n","Creating metadata for: SpinnerDolphin\n","Creating metadata for: StripedDolphin\n","Creating metadata for: Walrus\n","Creating metadata for: WeddellSeal\n","Creating metadata for: White_beakedDolphin\n","Creating metadata for: White_sidedDolphin\n"]}]}]}